app:
  description: ''
  icon: "\U0001F916"
  icon_background: '#FFEAD5'
  mode: advanced-chat
  name: translation-agent
workflow:
  features:
    file_upload:
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
    opening_statement: ''
    retriever_resource:
      enabled: false
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        isInIteration: false
        sourceType: start
        targetType: tool
      id: 1718766823150-source-1718786476648-target
      source: '1718766823150'
      sourceHandle: source
      target: '1718786476648'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: tool
        targetType: code
      id: 1718786476648-source-1718786953172-target
      source: '1718786476648'
      sourceHandle: source
      target: '1718786953172'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: if-else
      id: 1718786953172-source-1718788794085-target
      source: '1718786953172'
      sourceHandle: source
      target: '1718788794085'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: llm
      id: 1718788794085-true-1718788868716-target
      source: '1718788794085'
      sourceHandle: 'true'
      target: '1718788868716'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: 1718788868716-source-1718789183793-target
      source: '1718788868716'
      sourceHandle: source
      target: '1718789183793'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: llm
      id: 1718789183793-source-1718805585642-target
      source: '1718789183793'
      sourceHandle: source
      target: '1718805585642'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: answer
      id: 1718805585642-source-1718805720007-target
      source: '1718805585642'
      sourceHandle: source
      target: '1718805720007'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: if-else
        targetType: iteration
      id: 1718788794085-false-1718807423090-target
      source: '1718788794085'
      sourceHandle: 'false'
      target: '1718807423090'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: true
        iteration_id: '1718807423090'
        sourceType: code
        targetType: llm
      id: 1718807427345-source-1718808081768-target
      source: '1718807427345'
      sourceHandle: source
      target: '1718808081768'
      targetHandle: target
      type: custom
      zIndex: 1002
    - data:
        isInIteration: false
        sourceType: iteration
        targetType: iteration
      id: 1718807423090-source-1718809268778-target
      source: '1718807423090'
      sourceHandle: source
      target: '1718809268778'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: true
        iteration_id: '1718809268778'
        sourceType: code
        targetType: llm
      id: 1718809306606-source-1718809317876-target
      source: '1718809306606'
      sourceHandle: source
      target: '1718809317876'
      targetHandle: target
      type: custom
      zIndex: 1002
    - data:
        isInIteration: false
        sourceType: iteration
        targetType: iteration
      id: 1718809268778-source-1718809818791-target
      source: '1718809268778'
      sourceHandle: source
      target: '1718809818791'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: true
        iteration_id: '1718809818791'
        sourceType: code
        targetType: llm
      id: 1718809857875-source-1718809860763-target
      source: '1718809857875'
      sourceHandle: source
      target: '1718809860763'
      targetHandle: target
      type: custom
      zIndex: 1002
    - data:
        isInIteration: false
        sourceType: iteration
        targetType: code
      id: 1718809818791-source-1718810226408-target
      source: '1718809818791'
      sourceHandle: source
      target: '1718810226408'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: code
        targetType: answer
      id: 1718810226408-source-1718810281891-target
      source: '1718810226408'
      sourceHandle: source
      target: '1718810281891'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        desc: ''
        selected: false
        title: "\u5F00\u59CB"
        type: start
        variables:
        - label: source_lang
          max_length: 48
          options: []
          required: true
          type: text-input
          variable: source_lang
        - label: target_lang
          max_length: 48
          options: []
          required: true
          type: text-input
          variable: target_lang
      height: 116
      id: '1718766823150'
      position:
        x: 30
        y: 262.5
      positionAbsolute:
        x: 30
        y: 262.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        provider_id: 59c0521d-70ec-40de-aa6d-1f7cb497f77d
        provider_name: sourceSplit
        provider_type: api
        selected: false
        title: split
        tool_configurations: {}
        tool_label: sourceSplit_post
        tool_name: sourceSplit_post
        tool_parameters:
          max_chunk:
            type: constant
            value: '1000'
          max_token_per_chunk:
            type: constant
            value: '1000'
          source_text:
            type: mixed
            value: '{{#sys.query#}}'
        type: tool
      height: 54
      id: '1718786476648'
      position:
        x: 333
        y: 262.5
      positionAbsolute:
        x: 333
        y: 262.5
      selected: true
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "\ndef main(text: str) -> dict:\n    import json\n    data = json.loads(text)\n\
          \    return {\n        \"result\": data['text'],\n        \"num\": len(data['text'])\n\
          \    }\n    \n"
        code_language: python3
        desc: ''
        outputs:
          num:
            children: null
            type: number
          result:
            children: null
            type: array[string]
        selected: false
        title: parse
        type: code
        variables:
        - value_selector:
          - '1718786476648'
          - text
          variable: text
      height: 54
      id: '1718786953172'
      position:
        x: 637.5100257722306
        y: 262.5
      positionAbsolute:
        x: 637.5100257722306
        y: 262.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        conditions:
        - comparison_operator: '='
          id: '1718788796403'
          value: '1'
          variable_selector:
          - '1718786953172'
          - num
        desc: ''
        logical_operator: and
        selected: false
        title: "\u6761\u4EF6\u5206\u652F"
        type: if-else
      height: 126
      id: '1718788794085'
      position:
        x: 939
        y: 262.5
      positionAbsolute:
        x: 939
        y: 262.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: qwen-max
          provider: tongyi
        prompt_template:
        - id: 2c2750f9-02dc-49f7-9bf0-4fa90b19261f
          role: system
          text: You are an expert linguist, specializing in translation from {{#1718766823150.source_lang#}}
            to {{#1718766823150.target_lang#}}."
        - id: e9bc0d8b-b3a7-42bc-80ed-b60eeae51de7
          role: user
          text: "This is an {{#1718766823150.source_lang#}}  to{{#1718766823150.target_lang#}}\
            \ translation, please provide the {{#1718766823150.target_lang#}} translation\
            \ for this text. \n\nDo not provide any explanations or text apart from\
            \ the translation.\n{{#1718766823150.source_lang#}}: {{#sys.query#}}\n\
            \n\n{{#1718766823150.target_lang#}}:"
        selected: false
        title: one_chunk_initial_translation
        type: llm
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1718788868716'
      position:
        x: 1242
        y: 262.5
      positionAbsolute:
        x: 1242
        y: 262.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: qwen-max
          provider: tongyi
        prompt_template:
        - id: 87deb667-7b98-4103-92f0-ffb8e88f9aae
          role: system
          text: 'You are an expert linguist specializing in translation from {{#1718766823150.source_lang#}}
            to {{#1718766823150.target_lang#}}.

            You will be provided with a source text and its translation and your goal
            is to improve the translation.'
        - id: f015380e-e4c1-4411-92c8-f70423211e72
          role: user
          text: "Your task is to carefully read a source text and a translation from\
            \ {{#1718766823150.source_lang#}} to {{#1718766823150.target_lang#}},\
            \ and then give constructive criticism and helpful suggestions to improve\
            \ the translation. \n\n\nThe source text and initial translation, delimited\
            \ by XML tags <SOURCE_TEXT></SOURCE_TEXT> and <TRANSLATION></TRANSLATION>,\
            \ are as follows:\n<SOURCE_TEXT>\n{{#sys.query#}}\n</SOURCE_TEXT>\n<TRANSLATION>\n\
            {{#1718788868716.text#}}\n</TRANSLATION>\nWhen writing suggestions, pay\
            \ attention to whether there are ways to improve the translation's \n\
            (i) accuracy (by correcting errors of addition, mistranslation, omission,\
            \ or untranslated text),\n(ii) fluency (by applying {{#1718766823150.target_lang#}}\
            \ grammar, spelling and punctuation rules, and ensuring there are no unnecessary\
            \ repetitions),\n(iii) style (by ensuring the translations reflect the\
            \ style of the source text and takes into account any cultural context),\n\
            (iv) terminology (by ensuring terminology use is consistent and reflects\
            \ the source text domain; and by only ensuring you use equivalent idioms\
            \ {{#1718766823150.target_lang#}}.\nWrite a list of specific, helpful\
            \ and constructive suggestions for improving the translation.\nEach suggestion\
            \ should address one specific part of the translation.\nOutput only the\
            \ suggestions and nothing else."
        selected: false
        title: one_chunk_reflect_on_translation
        type: llm
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1718789183793'
      position:
        x: 1544.3781781690743
        y: 262.5
      positionAbsolute:
        x: 1544.3781781690743
        y: 262.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: qwen-max
          provider: tongyi
        prompt_template:
        - id: d7a2bd0c-9e82-4cd6-92ea-c9b71530666f
          role: system
          text: You are an expert linguist, specializing in translation editing from
            {{#1718766823150.source_lang#}} to {{#1718766823150.target_lang#}}.
        - id: b478a108-d849-4e5b-bd76-a67c0f02b06d
          role: user
          text: "Your task is to carefully read, then edit, a translation from {{#1718766823150.source_lang#}}\
            \ to {{#1718766823150.target_lang#}}, taking into\n\naccount a list of\
            \ expert suggestions and constructive criticisms.\nThe source text, the\
            \ initial translation, and the expert linguist suggestions are delimited\
            \ by XML tags <SOURCE_TEXT></SOURCE_TEXT>, <TRANSLATION></TRANSLATION>\
            \ and <EXPERT_SUGGESTIONS></EXPERT_SUGGESTIONS> \\\nas follows:\n<SOURCE_TEXT>\n\
            {{#sys.query#}}\n</SOURCE_TEXT>\n<TRANSLATION>\n{{#1718788868716.text#}}\n\
            </TRANSLATION>\n<EXPERT_SUGGESTIONS>\n{{#1718789183793.text#}}\n</EXPERT_SUGGESTIONS>\n\
            Please take into account the expert suggestions when editing the translation.\
            \ Edit the translation by ensuring:\n(i) accuracy (by correcting errors\
            \ of addition, mistranslation, omission, or untranslated text),\n(ii)\
            \ fluency (by applying {{#1718766823150.target_lang#}} grammar, spelling\
            \ and punctuation rules and ensuring there are no unnecessary repetitions),\
            \ \n(iii) style (by ensuring the translations reflect the style of the\
            \ source text)\n(iv) terminology (inappropriate for context, inconsistent\
            \ use), or\n(v) other errors.\nOutput only the new translation and nothing\
            \ else."
        selected: false
        title: one_chunk_improve_translation
        type: llm
        variables: []
        vision:
          enabled: false
      height: 98
      id: '1718805585642'
      position:
        x: 1849.278607244183
        y: 262.5
      positionAbsolute:
        x: 1849.278607244183
        y: 262.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1718805585642.text#}}'
        desc: ''
        selected: false
        title: "\u76F4\u63A5\u56DE\u590D"
        type: answer
        variables: []
      height: 107
      id: '1718805720007'
      position:
        x: 2151
        y: 262.5
      positionAbsolute:
        x: 2151
        y: 262.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        desc: ''
        height: 202
        iterator_selector:
        - '1718786953172'
        - result
        output_selector:
        - '1718808081768'
        - text
        output_type: array[string]
        selected: false
        startNodeType: code
        start_node_id: '1718807427345'
        title: initial
        type: iteration
        width: 679
      height: 202
      id: '1718807423090'
      position:
        x: 1242
        y: 398.5
      positionAbsolute:
        x: 1242
        y: 398.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 679
      zIndex: 1
    - data:
        code: "def main(\n    source_lang: str,\n    target_lang: str,\n    source_text_chunk_index:\
          \ int,\n    source_text_chunks: list,\n) -> dict:\n    system_message =\
          \ f\"You are an expert linguist, specializing in translation from {source_lang}\
          \ to {target_lang}.\"\n    translation_prompt = \"\"\"Your task is provide\
          \ a professional translation from {source_lang} to {target_lang} of PART\
          \ of a text.\n\nThe source text is below, delimited by XML tags <SOURCE_TEXT>\
          \ and </SOURCE_TEXT>. Translate only the part within the source text\ndelimited\
          \ by <TRANSLATE_THIS> and </TRANSLATE_THIS>. You can use the rest of the\
          \ source text as context, but do not translate any\nof the other text. Do\
          \ not output anything other than the translation of the indicated part of\
          \ the text.\n\n<SOURCE_TEXT>\n{tagged_text}\n</SOURCE_TEXT>\n\nTo reiterate,\
          \ you should translate only this part of the text, shown here again between\
          \ <TRANSLATE_THIS> and </TRANSLATE_THIS>:\n<TRANSLATE_THIS>\n{chunk_to_translate}\n\
          </TRANSLATE_THIS>\n\nOutput only the translation of the portion you are\
          \ asked to translate, and nothing else.\n\"\"\"\n    tagged_text = (\n \
          \       \"\".join(source_text_chunks[0:source_text_chunk_index])\n     \
          \   + \"<TRANSLATE_THIS>\"\n        + source_text_chunks[source_text_chunk_index]\n\
          \        + \"</TRANSLATE_THIS>\"\n        + \"\".join(source_text_chunks[source_text_chunk_index\
          \ + 1 :])\n    )\n    prompt = translation_prompt.format(\n        source_lang=source_lang,\n\
          \        target_lang=target_lang,\n        tagged_text=tagged_text,\n  \
          \      chunk_to_translate=source_text_chunks[source_text_chunk_index],\n\
          \    )\n    return {\"prompt\": prompt, \"system_message\": system_message}\n"
        code_language: python3
        desc: ''
        isInIteration: true
        isIterationStart: true
        iteration_id: '1718807423090'
        outputs:
          prompt:
            children: null
            type: string
          system_message:
            children: null
            type: string
        selected: false
        title: handle_multichunk
        type: code
        variables:
        - value_selector:
          - '1718766823150'
          - source_lang
          variable: source_lang
        - value_selector:
          - '1718766823150'
          - target_lang
          variable: target_lang
        - value_selector:
          - '1718807423090'
          - index
          variable: source_text_chunk_index
        - value_selector:
          - '1718786953172'
          - result
          variable: source_text_chunks
      extent: parent
      height: 54
      id: '1718807427345'
      parentId: '1718807423090'
      position:
        x: 117
        y: 85
      positionAbsolute:
        x: 1359
        y: 483.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
      zIndex: 1001
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        isInIteration: true
        iteration_id: '1718807423090'
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: qwen-max
          provider: tongyi
        prompt_template:
        - id: 605e0e75-e92e-461c-87bc-83c963a915bb
          role: system
          text: '{{#1718807427345.system_message#}}'
        - id: 3b8f03a3-9be4-4c86-98b9-93a68d7f5edb
          role: user
          text: '{{#1718807427345.prompt#}}'
        selected: false
        title: multichunk_initial_translation
        type: llm
        variables: []
        vision:
          enabled: false
      extent: parent
      height: 98
      id: '1718808081768'
      parentId: '1718807423090'
      position:
        x: 420
        y: 85
      positionAbsolute:
        x: 1662
        y: 483.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
      zIndex: 1002
    - data:
        desc: ''
        height: 202
        iterator_selector:
        - '1718807423090'
        - output
        output_selector:
        - '1718809317876'
        - text
        output_type: array[string]
        selected: false
        startNodeType: code
        start_node_id: '1718809306606'
        title: reflect
        type: iteration
        width: 679
      height: 202
      id: '1718809268778'
      position:
        x: 1981
        y: 398.5
      positionAbsolute:
        x: 1981
        y: 398.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 679
      zIndex: 1
    - data:
        code: "def main(\n    source_lang: str,\n    target_lang: str,\n    source_text_chunks:\
          \ list,\n    source_text_chunk_index: int,\n    translation_1_chunks: list,\n\
          ) -> dict:\n    system_message = f\"You are an expert linguist specializing\
          \ in translation from {source_lang} to {target_lang}. \\\nYou will be provided\
          \ with a source text and its translation and your goal is to improve the\
          \ translation.\"\n    reflection_prompt = \"\"\"Your task is to carefully\
          \ read a source text and part of a translation of that text from {source_lang}\
          \ to {target_lang}, and then give constructive criticism and helpful suggestions\
          \ for improving the translation.\n\nThe source text is below, delimited\
          \ by XML tags <SOURCE_TEXT> and </SOURCE_TEXT>, and the part that has been\
          \ translated\nis delimited by <TRANSLATE_THIS> and </TRANSLATE_THIS> within\
          \ the source text. You can use the rest of the source text\nas context for\
          \ critiquing the translated part.\n\n<SOURCE_TEXT>\n{tagged_text}\n</SOURCE_TEXT>\n\
          \nTo reiterate, only part of the text is being translated, shown here again\
          \ between <TRANSLATE_THIS> and </TRANSLATE_THIS>:\n<TRANSLATE_THIS>\n{chunk_to_translate}\n\
          </TRANSLATE_THIS>\n\nThe translation of the indicated part, delimited below\
          \ by <TRANSLATION> and </TRANSLATION>, is as follows:\n<TRANSLATION>\n{translation_1_chunk}\n\
          </TRANSLATION>\n\nWhen writing suggestions, pay attention to whether there\
          \ are ways to improve the translation's:\\n\\\n(i) accuracy (by correcting\
          \ errors of addition, mistranslation, omission, or untranslated text),\\\
          n\\\n(ii) fluency (by applying {target_lang} grammar, spelling and punctuation\
          \ rules, and ensuring there are no unnecessary repetitions),\\n\\\n(iii)\
          \ style (by ensuring the translations reflect the style of the source text\
          \ and takes into account any cultural context),\\n\\\n(iv) terminology (by\
          \ ensuring terminology use is consistent and reflects the source text domain;\
          \ and by only ensuring you use equivalent idioms {target_lang}).\\n\\\n\n\
          Write a list of specific, helpful and constructive suggestions for improving\
          \ the translation.\nEach suggestion should address one specific part of\
          \ the translation.\nOutput only the suggestions and nothing else.\"\"\"\n\
          \    tagged_text = (\n        \"\".join(source_text_chunks[0:source_text_chunk_index])\n\
          \        + \"<TRANSLATE_THIS>\"\n        + source_text_chunks[source_text_chunk_index]\n\
          \        + \"</TRANSLATE_THIS>\"\n        + \"\".join(source_text_chunks[source_text_chunk_index\
          \ + 1 :])\n    )\n    prompt = reflection_prompt.format(\n        source_lang=source_lang,\n\
          \        target_lang=target_lang,\n        tagged_text=tagged_text,\n  \
          \      chunk_to_translate=source_text_chunks[source_text_chunk_index],\n\
          \        translation_1_chunk=translation_1_chunks[source_text_chunk_index],\n\
          \    )\n    return {\"prompt\": prompt, \"system_message\": system_message}\n"
        code_language: python3
        desc: ''
        isInIteration: true
        isIterationStart: true
        iteration_id: '1718809268778'
        outputs:
          prompt:
            children: null
            type: string
          system_message:
            children: null
            type: string
        selected: false
        title: handle_translation_1_chunks
        type: code
        variables:
        - value_selector:
          - '1718766823150'
          - source_lang
          variable: source_lang
        - value_selector:
          - '1718766823150'
          - target_lang
          variable: target_lang
        - value_selector:
          - '1718786953172'
          - result
          variable: source_text_chunks
        - value_selector:
          - '1718809268778'
          - index
          variable: source_text_chunk_index
        - value_selector:
          - '1718807423090'
          - output
          variable: translation_1_chunks
      extent: parent
      height: 54
      id: '1718809306606'
      parentId: '1718809268778'
      position:
        x: 117
        y: 85
      positionAbsolute:
        x: 2098
        y: 483.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
      zIndex: 1001
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        isInIteration: true
        iteration_id: '1718809268778'
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: qwen-max
          provider: tongyi
        prompt_template:
        - id: dec17628-dbbb-495b-96ff-cb5e70cb9852
          role: system
          text: '{{#1718809306606.system_message#}}'
        - role: user
          text: '{{#1718809306606.prompt#}}'
        selected: false
        title: multichunk_reflect_on_translation
        type: llm
        variables: []
        vision:
          enabled: false
      extent: parent
      height: 98
      id: '1718809317876'
      parentId: '1718809268778'
      position:
        x: 420
        y: 85
      positionAbsolute:
        x: 2401
        y: 483.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
      zIndex: 1002
    - data:
        desc: ''
        height: 202
        iterator_selector:
        - '1718809268778'
        - output
        output_selector:
        - '1718809860763'
        - text
        output_type: array[string]
        selected: false
        startNodeType: code
        start_node_id: '1718809857875'
        title: improve
        type: iteration
        width: 679
      height: 202
      id: '1718809818791'
      position:
        x: 2720
        y: 398.5
      positionAbsolute:
        x: 2720
        y: 398.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 679
      zIndex: 1
    - data:
        code: "\ndef main(\n    source_lang: str,\n    target_lang: str,\n    source_text_chunks:\
          \ list,\n    translation_1_chunks: list,\n    source_text_chunk_index: int,\n\
          \    reflection_chunks: list,\n) -> dict:\n    system_message = f\"You are\
          \ an expert linguist, specializing in translation editing from {source_lang}\
          \ to {target_lang}.\"\n    improvement_prompt = \"\"\"Your task is to carefully\
          \ read, then improve, a translation from {source_lang} to {target_lang},\
          \ taking into\naccount a set of expert suggestions and constructive critisms.\
          \ Below, the source text, initial translation, and expert suggestions are\
          \ provided.\n\nThe source text is below, delimited by XML tags <SOURCE_TEXT>\
          \ and </SOURCE_TEXT>, and the part that has been translated\nis delimited\
          \ by <TRANSLATE_THIS> and </TRANSLATE_THIS> within the source text. You\
          \ can use the rest of the source text\nas context, but need to provide a\
          \ translation only of the part indicated by <TRANSLATE_THIS> and </TRANSLATE_THIS>.\n\
          \n<SOURCE_TEXT>\n{tagged_text}\n</SOURCE_TEXT>\n\nTo reiterate, only part\
          \ of the text is being translated, shown here again between <TRANSLATE_THIS>\
          \ and </TRANSLATE_THIS>:\n<TRANSLATE_THIS>\n{chunk_to_translate}\n</TRANSLATE_THIS>\n\
          \nThe translation of the indicated part, delimited below by <TRANSLATION>\
          \ and </TRANSLATION>, is as follows:\n<TRANSLATION>\n{translation_1_chunk}\n\
          </TRANSLATION>\n\nThe expert translations of the indicated part, delimited\
          \ below by <EXPERT_SUGGESTIONS> and </EXPERT_SUGGESTIONS>, is as follows:\n\
          <EXPERT_SUGGESTIONS>\n{reflection_chunk}\n</EXPERT_SUGGESTIONS>\n\nTaking\
          \ into account the expert suggestions rewrite the translation to improve\
          \ it, paying attention\nto whether there are ways to improve the translation's\n\
          \n(i) accuracy (by correcting errors of addition, mistranslation, omission,\
          \ or untranslated text),\n(ii) fluency (by applying {target_lang} grammar,\
          \ spelling and punctuation rules and ensuring there are no unnecessary repetitions),\
          \ \\\n(iii) style (by ensuring the translations reflect the style of the\
          \ source text)\n(iv) terminology (inappropriate for context, inconsistent\
          \ use), or\n(v) other errors.\n\nOutput only the new translation of the\
          \ indicated part and nothing else.\"\"\"\n    tagged_text = (\n        \"\
          \".join(source_text_chunks[0:source_text_chunk_index])\n        + \"<TRANSLATE_THIS>\"\
          \n        + source_text_chunks[source_text_chunk_index]\n        + \"</TRANSLATE_THIS>\"\
          \n        + \"\".join(source_text_chunks[source_text_chunk_index + 1 :])\n\
          \    )\n    prompt = improvement_prompt.format(\n        source_lang=source_lang,\n\
          \        target_lang=target_lang,\n        tagged_text=tagged_text,\n  \
          \      chunk_to_translate=source_text_chunks[source_text_chunk_index],\n\
          \        translation_1_chunk=translation_1_chunks[source_text_chunk_index],\n\
          \        reflection_chunk=reflection_chunks[source_text_chunk_index],\n\
          \    )\n    return {\"prompt\": prompt, \"system_message\": system_message}\n"
        code_language: python3
        desc: ''
        isInIteration: true
        isIterationStart: true
        iteration_id: '1718809818791'
        outputs:
          prompt:
            children: null
            type: string
          system_message:
            children: null
            type: string
        selected: false
        title: multichunk_improve_translation
        type: code
        variables:
        - value_selector:
          - '1718766823150'
          - source_lang
          variable: source_lang
        - value_selector:
          - '1718766823150'
          - target_lang
          variable: target_lang
        - value_selector:
          - '1718786953172'
          - result
          variable: source_text_chunks
        - value_selector:
          - '1718807423090'
          - output
          variable: translation_1_chunks
        - value_selector:
          - '1718809818791'
          - index
          variable: source_text_chunk_index
        - value_selector:
          - '1718809268778'
          - output
          variable: reflection_chunks
      extent: parent
      height: 54
      id: '1718809857875'
      parentId: '1718809818791'
      position:
        x: 117
        y: 85
      positionAbsolute:
        x: 2837
        y: 483.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
      zIndex: 1001
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        isInIteration: true
        iteration_id: '1718809818791'
        model:
          completion_params:
            temperature: 0.7
          mode: chat
          name: qwen-max
          provider: tongyi
        prompt_template:
        - id: 0a1b196d-0bfb-4754-8537-57f8df592a1b
          role: system
          text: '{{#1718809857875.system_message#}}'
        - id: 3ae36d68-4e07-4e59-9c2f-0b138078e412
          role: user
          text: '{{#1718809857875.prompt#}}'
        selected: false
        title: multichunk_improve_translation
        type: llm
        variables: []
        vision:
          enabled: false
      extent: parent
      height: 98
      id: '1718809860763'
      parentId: '1718809818791'
      position:
        x: 420
        y: 85
      positionAbsolute:
        x: 3140
        y: 483.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
      zIndex: 1002
    - data:
        code: "\ndef main(text: list) -> dict:\n    return {\n        \"result\":\
          \ \"\".join(text)\n    }\n"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: string
        selected: false
        title: join
        type: code
        variables:
        - value_selector:
          - '1718809818791'
          - output
          variable: text
      height: 54
      id: '1718810226408'
      position:
        x: 3459
        y: 398.5
      positionAbsolute:
        x: 3459
        y: 398.5
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1718810226408.result#}}'
        desc: ''
        selected: false
        title: "\u76F4\u63A5\u56DE\u590D 2"
        type: answer
        variables: []
      height: 107
      id: '1718810281891'
      position:
        x: 3762
        y: 398.5
      positionAbsolute:
        x: 3762
        y: 398.5
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: -1003.2740768428846
      y: 301.6264302758597
      zoom: 0.680858463188602
